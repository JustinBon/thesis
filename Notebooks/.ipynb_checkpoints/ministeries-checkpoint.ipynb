{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "catholic-bouquet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\justin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\cupy\\_environment.py:214: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  'CUDA path could not be detected.'\n",
      "c:\\users\\justin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\cupy\\_environment.py:214: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  'CUDA path could not be detected.'\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span, DocBin\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "norwegian-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"nl_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "attempted-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_ministries = spacy.load(\"..\\\\data\\\\spacy labeled\\\\output\\\\model-last\")\n",
    "df = pd.read_csv('..\\\\data\\\\ocred\\\\files_df.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-serial",
   "metadata": {},
   "source": [
    "This notebook is for rq 2.2.2\n",
    "\n",
    "There were a lot of itterations for this extractor. These will be first. At the end, the extractor that was used is implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "traditional-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printHilight(string):\n",
    "    print('\\x1b[1;31m'+string + ' ' +'\\x1b[0m', end='')\n",
    "\n",
    "def printHilightUnderline(string):\n",
    "    print('\\033[4m\\033[96m'+string  +'\\033[96m\\x1b[0m' + ' ', end='')\n",
    "    \n",
    "def inputHandling(message):\n",
    "    while(True):\n",
    "        i = input(message)\n",
    "        if i == 'q':\n",
    "            return -1\n",
    "        \n",
    "        elif i == '':\n",
    "            return 0\n",
    "        \n",
    "        try:\n",
    "            i = int(i)\n",
    "            return i\n",
    "        \n",
    "        except:\n",
    "            print(\"input number, q or nothing\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "spoken-jewel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates f1, precision and recall with the partial method\n",
    "def calcResultsMinistries(r):\n",
    "    precision = (r['correct'] + (0.5 * r['partial'])) / (r['correct']+r['incorrect']+r['spurious'])\n",
    "    recall = (r['correct'] + (0.5 * r['partial'])) / (r['correct']+r['incorrect']+r['missing'])\n",
    "    f1 = 2 * ((recall * precision)/(recall + precision))\n",
    "    results['precision'] = precision\n",
    "    results['recall'] = recall\n",
    "    results['f1'] = f1 \n",
    "    print(f'precision = {precision}, recall = {recall}, f1 = {f1}')\n",
    "    print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "utility-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of current dutch ministries and their abbriviations\n",
    "def getMinisteries(getList):\n",
    "    \n",
    "    # get html of the wiki page of dutch ministries\n",
    "    page = requests.get('https://nl.wikipedia.org/wiki/Lijst_van_Nederlandse_ministeries')\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find_all(\"td\")[-1]\n",
    "    \n",
    "    # get all links in the html\n",
    "    results.find_all('a', href = True)\n",
    "    wikis = {}\n",
    "    \n",
    "    abrr = []\n",
    "    for item in str(results.find_all('p')[0]).split('\\n')[:-1] + str(results.find_all('p')[1]).split('\\n')[1:-1]:\n",
    "        temp = re.findall('(?<=\\()(.*?)(?=\\))', item)\n",
    "        if temp == []:\n",
    "            abrr.append(None)\n",
    "        elif temp[-1] == 'Nederland':\n",
    "            abrr.append(None)\n",
    "            if 'Overzeese Gebiedsdelen' in item:\n",
    "                abrr.append(None)\n",
    "        else:\n",
    "            abrr.append(temp[-1].replace('&amp;', '&'))\n",
    "\n",
    "\n",
    "    counter = 0\n",
    "    for ministerie in results.find_all('a')[:12]:\n",
    "        wikis[ministerie.text] = {'Link': 'https://nl.wikipedia.org' + ministerie['href'], 'Abbriviation' : abrr[counter]}\n",
    "        counter += 1\n",
    "    \n",
    "    if getList:\n",
    "        minList = list(wikis.keys()) + [wikis[x]['Abbriviation'] for x in wikis.keys()]\n",
    "        for x in minList:\n",
    "            temp+=x.replace(',', '').split(' ')\n",
    "\n",
    "        return [x.lower() for x in temp if x != 'en' and x != ''] + ['ezk']\n",
    "    else:\n",
    "        return wikis\n",
    "    \n",
    "minList = getMinisteries(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "horizontal-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def showMatchesOld(text, regexMatches, minList):   \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.split(' ')\n",
    "    \n",
    "    for word in text:\n",
    "        if word in regexMatches:\n",
    "            printHilight(word)\n",
    "        elif word in minList:\n",
    "            printHilightUnderline(word)\n",
    "        else:\n",
    "            print(word, end=' ')\n",
    "\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "civic-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMinisteries(minList, useAbbr = True, lookForMin = True):\n",
    "    \n",
    "    ministeries = getMinisteries(False)\n",
    "    abrr = [ministeries[x]['Abbriviation'] for x in ministeries if ministeries[x]['Abbriviation'] != None]\n",
    "    \n",
    "    if useAbbr:\n",
    "        allMinisteries = list(ministeries.keys()) + abrr\n",
    "    else:\n",
    "        allMinisteries = list(ministeries.keys())\n",
    "    \n",
    "    \n",
    "    results = {\n",
    "        'correct':0,\n",
    "        'incorrect':0,\n",
    "        'partial':0,\n",
    "        'missing':0,\n",
    "        'spurious':0,\n",
    "    }\n",
    "    \n",
    "\n",
    "    while(True):\n",
    "        try:\n",
    "            sample = df.sample(1)\n",
    "            text = sample.text.values[0]\n",
    "            text = re.sub('\\n+', '\\n', text)\n",
    "            text = re.sub(' +', ' ', text)\n",
    "            for m in minList:\n",
    "                if m in text.split(' '):\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            print(sum(list(results.values())[:4] ))\n",
    "            print(sample.name.values[0], sample.page.values[0], '\\n\\n')\n",
    "            \n",
    "            \n",
    "            for ministerie in allMinisteries:\n",
    "                \n",
    "                if lookForMin:                \n",
    "                    temp = re.findall('ministerie van ' + ministerie.lower(), text)\n",
    "                else:\n",
    "                    temp = re.findall(ministerie.lower(), text)\n",
    "                    \n",
    "                if temp != []:\n",
    "                    found[fileName][ministerie.lower()] = len(temp)\n",
    "            \n",
    "            showMatchesMinistries(text, found, minList)\n",
    "\n",
    "            for case in list(results.keys()):\n",
    "                result = inputHandling(case)\n",
    "                if result == -1:\n",
    "                    return results\n",
    "                else:\n",
    "                    results[case] += result\n",
    "\n",
    "            clear_output()\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks for ministerie van ...\n",
    "\n",
    "results = findMinisteries(minList)\n",
    "results = calcResultsMinistries(results)\n",
    "\n",
    "with open('..\\\\data\\\\results\\\\dates_min_old_full.json', 'w') as f:\n",
    "    json.dump(results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks for mentions of ministries\n",
    "\n",
    "results = findMinisteries(minList, True, False)\n",
    "results = calcResultsMinistries(results)\n",
    "\n",
    "with open('..\\\\data\\\\results\\\\dates_min_old_no_prefix.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks for mentions of ministries without abbriviations\n",
    "\n",
    "results = findMinisteries(minList, False, False)\n",
    "results = calcResultsMinistries(results)\n",
    "\n",
    "with open('..\\\\data\\\\results\\\\dates_min_old_empty.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-contest",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "It is easy to find correct matches for ministeries when using gazetteers. The precision of this test is 0.882. Most all of the matches that were found are actually ministeries. However the recall of the matcher is very bad at 0.377. The matcher doesnt even find half of all the ministeries that were in the text. The reason for this is clear. It has to do with summations as abbriviations. \n",
    "\n",
    "Within the texts, a lot of summations of ministeries are used. For example: \"de ministeries van VWSS, JenV, en BZK\". In this case none of these will abbreviations of ministeries will be matched. The matcher looks for \"ministerie van {name of ministerie}\". VWSS will not be matched because ministeries is plural in stead of singular and JenV and BZK will not be matched because these are not preceded by \"ministerie van \". A solution for this could be to not look for the preceding \"ministerie van \", however, if this is done, all of those abbriviations will be matched outside of context. The abbriviation of the ministery of defence for example, is \"def\" so the matcher will find all occurences of the three letters \"def\". With this modification the recall will actually increase to a whopping 0.458 but the precision will decrease to a meager 0.122. So this is not a solution. \n",
    "\n",
    "I also tested if the it would help to at least find the VWSS in the example by also looking at the plural of ministerie but that decreased the precision more than it increased the recall. \n",
    "\n",
    "The last solution is the \"best\". This completely ignores the abbriviations and just looks for the names if the ministeries without the preceding \"ministerie van \". This actually increases the recall to 0.435 but it also decreases the precision to 0.732. This is because it will also find random mentions of the words \"financien\" and \"defensie\" and others. I don't think that that is worth it. In this case I would rather have more confidance in what I what I find to be correct than finding everything."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-helena",
   "metadata": {},
   "source": [
    "Now for the best extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-agency",
   "metadata": {},
   "source": [
    "## Labeling new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printHilight(string):\n",
    "    print('\\x1b[1;31m'+string + ' ' +'\\x1b[0m', end='')\n",
    "\n",
    "# this function allows a user to label new data\n",
    "def showTokens(text, allMinisteries):\n",
    "\n",
    "    try:\n",
    "        text = re.sub(' +', ' ', text)\n",
    "        text = text.replace('\\n', ' ')\n",
    "    except:\n",
    "        pass\n",
    "    doc = nlp(str(text))\n",
    "    # get list of entities as strings\n",
    "    listTokens = [str(ent.text) for ent in doc.ents]\n",
    "\n",
    "    # control variables\n",
    "    nToken = 0\n",
    "    tempTokens = []\n",
    "    lenTemp = 0\n",
    "\n",
    "    # loop over tokens\n",
    "    for i in range(len(doc)):\n",
    "\n",
    "        # get string representation of token and add to a temporary list with token index\n",
    "        t = str(doc[i])\n",
    "        tempTokens.append((t, nToken))\n",
    "\n",
    "        # increase n tokens and length of all strings in tempTokens\n",
    "        nToken += 1\n",
    "        lenTemp += (len(t) + 1)\n",
    "\n",
    "        # once lenght of all strings in tempTokens is 100 or larger, start printing the line\n",
    "        if lenTemp >= 100 or i >= len(doc) - 1:\n",
    "\n",
    "            # print the index for every token\n",
    "            for word in tempTokens:\n",
    "\n",
    "                # if index number is more chars than the token, dont print the index number\n",
    "                if len(word[0]) < len(str(word[1])):\n",
    "                    print(' ' * (len(word[0]) + 1), end='')\n",
    "\n",
    "                # else just print index number plus a number of spaces\n",
    "                else:\n",
    "                    print(word[1], ' ' * (len(word[0]) - len(str(word[1]))), end='')\n",
    "            print('')\n",
    "\n",
    "            # print all tokens\n",
    "            for word in tempTokens:\n",
    "\n",
    "                # highlight tokens in red if named entity\n",
    "                if word[0].lower() in allMinisteries + ['ministerie', 'ministeries']:\n",
    "                    printHilight(word[0])\n",
    "                else:\n",
    "                    print(word[0] + ' ', end='')\n",
    "\n",
    "            # add some space between lines\n",
    "            print('\\n\\n')\n",
    "\n",
    "            # reset control variables\n",
    "            tempTokens = []\n",
    "            lenTemp = 0\n",
    "    \n",
    "    # inputs:\n",
    "    # no input: next page\n",
    "    # q: quit \n",
    "    # remove: remove last label\n",
    "    # number1 number2: adds a label from span number1 to number2\n",
    "    # everything else is invalid, you will be prompted again\n",
    "    \n",
    "    \n",
    "    newEnts = []\n",
    "    while True:\n",
    "        x = input()\n",
    "        if x == '':\n",
    "            break\n",
    "        elif x == 'q':\n",
    "            raise Exception(\"Stopped the program\")\n",
    "        elif x == 'remove':\n",
    "            del newEnts[-1]\n",
    "            print('Removed')\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            x = x.split()\n",
    "            newEnts.append(Span(doc, int(x[0]), int(x[1]), label='MINISTERIE'))\n",
    "            print(doc[int(x[0]):int(x[1])])\n",
    "        except:\n",
    "            print('Two numbers seperated by a space')\n",
    "            continue\n",
    "            \n",
    "        \n",
    "    try:\n",
    "        doc.ents = newEnts\n",
    "        clear_output()\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showText(df, n):\n",
    "    \n",
    "    ministeries = getMinisteries()\n",
    "    abrr = [ministeries[x]['Abbriviation'] for x in ministeries if ministeries[x]['Abbriviation'] != None]\n",
    "    allMinisteries = list(ministeries.keys()) + abrr\n",
    "    allMinisteries = [x.lower() for x in allMinisteries]\n",
    "    \n",
    "    samples = df.sample(n)\n",
    "    docs = list(samples.text.apply(lambda x: showTokens(x, allMinisteries)))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "\n",
    "for i in range(30):\n",
    "    docs += showText(df, 10)\n",
    "    print(f'done {i + 1}0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-indication",
   "metadata": {},
   "source": [
    "## Training updated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-symbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(docs)\n",
    "train_docs = docs[:len(docs) // 2]\n",
    "dev_docs = docs[len(docs) // 2:]\n",
    "\n",
    "# Create and save a collection of training docs\n",
    "train_docbin = DocBin(docs=train_docs)\n",
    "train_docbin.to_disk(\"..\\\\data\\\\spacy labeled\\\\train2.spacy\")\n",
    "# Create and save a collection of evaluation docs\n",
    "dev_docbin = DocBin(docs=dev_docs)\n",
    "dev_docbin.to_disk(\"..\\\\data\\\\spacy labeled\\\\dev2.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp1 = spacy.load(\"..\\\\data\\\\spacy labeled\\\\output\\\\model-last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-labor",
   "metadata": {},
   "source": [
    "## Evaluating new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "constant-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showMatchesMinistries(doc, minList):   \n",
    "    indexOfMatches = []\n",
    "    for ent in doc.ents:\n",
    "        for i in range(int(ent.start), int(ent.end)):\n",
    "            indexOfMatches.append(i)\n",
    "\n",
    "    indexOfMatches = set(indexOfMatches)\n",
    "\n",
    "    for token in doc:\n",
    "        flag = False\n",
    "        for mini in minList:\n",
    "            if token.text.lower() == mini:\n",
    "                flag = True\n",
    "                break\n",
    "        \n",
    "        if token.i in indexOfMatches:\n",
    "            printHilight(str(token.text))\n",
    "            \n",
    "        elif flag:\n",
    "            printHilightUnderline(str(token.text))\n",
    "            \n",
    "        else:\n",
    "            print(token, end=' ')\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "southeast-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateMinistries(nlp, minList):\n",
    "    # cor = exact match, inc = match is wrong (wrong bounds or label), mis = missing match, spu = found something that\n",
    "    # isnt a mactch, \n",
    "    if os.path.isfile('..\\\\data\\\\results\\\\ministries_results,json'):\n",
    "        with open('..\\\\data\\\\results\\\\ministries_results,json') as f:\n",
    "            results = json.load(f)\n",
    "        \n",
    "        pass\n",
    "    else:\n",
    "        results = {\n",
    "            'correct':0,\n",
    "            'incorrect':0,\n",
    "            'partial':0,\n",
    "            'missing':0,\n",
    "            'spurious':0,\n",
    "            'abbr' :0,\n",
    "            'ocr':0,\n",
    "            'whitespace':0,\n",
    "            'minister':0,\n",
    "            'other':0\n",
    "        }\n",
    "    \n",
    "    minList = set(minList)\n",
    "    while(True):\n",
    "        try:\n",
    "            sample = df.sample(1)\n",
    "            text = sample.text.values[0]\n",
    "            text = re.sub('\\n+', '\\n', text)\n",
    "            text = re.sub(' +', ' ', text)\n",
    "            for m in minList:\n",
    "                if m in text.split(' '):\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            print(sum(list(results.values())[:4] ))\n",
    "            print(sample.name.values[0], sample.page.values[0], '\\n\\n')\n",
    "            doc = nlp(text)\n",
    "            \n",
    "            showMatchesMinistries(doc, minList)\n",
    "\n",
    "            for case in list(results.keys())[:10]:\n",
    "                result = inputHandling(case)\n",
    "                if result == -1:\n",
    "                    return results\n",
    "                else:\n",
    "                    results[case] += result\n",
    "\n",
    "            clear_output()\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "literary-algorithm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "0272cdb141e62321341591f0959794a2_wob-documenten 679 \n",
      "\n",
      "\n",
      "zorgverlening . Kan de regering uitleggen wat zorgverleners kunnen verstaan onder richtinggevend in \n",
      " het licht van eventuele handhaving ? \n",
      " Zorgaanbieders zijn zelf verantwoordelijk voor het verlenen van goede of verantwoorde zorg als \n",
      " bedoeld in de Wet kwaliteit , klachten en geschillen zorg ( Wkkgz ) of de Jeugdwet . Goede of \n",
      " verantwoorde zorg is ( onder meer ) zorg overeenkomstig de kwaliteitsstandaarden en professionele \n",
      " standaarden , waaronder infectiepreventierichtlijnen . In de zorg worden daarnaast veel handreikingen \n",
      " opgesteld . Zoals in de memorie van toelichting is aangegeven zijn er sinds het uitbreken van de \n",
      " epidemie meerdere adviezen en handreikingen opgesteld door het veld die handvatten bieden voor de \n",
      " zorgaanbieders en zorgverleners om uitvoering te geven aan de RIVM-adviezen . Deze adviezen en \n",
      " handreikingen zijn richtinggevend voor goede zorgverlening ( zie p. 91 van de memorie van \n",
      " toelichting ) . Dit betekent dat zorgaanbieders vanuit hun professionaliteit dienen af te wegen of de \n",
      " handreiking goed past in hun situatie en bij de individuele patiënt . De IGJ houdt hier in haar toezicht \n",
      " rekening mee . \n",
      " 155 - D66 \n",
      " In hoeverre zal hierop gehandhaafd worden met schriftelijke aanwijzingen en boetes ? \n",
      " De minister van \u001b[4m\u001b[96mVWS\u001b[96m\u001b[0m of de IGJ kan gebruikmaken van de instrumenten die hen ter beschikking staan , \n",
      " zoals een aanwijzing of bevel als bedoeld in artikel 580 , tweede lid . Als in een concreet geval een \n",
      " aanwijzing als bedoeld in artikel 580 , tweede lid , wordt gegeven , worden de adviezen en \n",
      " handreikingen als richtinggevend voor goede zorgverlening beschouwd , waarvan beargumenteerd kan \n",
      " worden afgeweken ( zie ook p. 91 , eerste alinea , van de memorie van toelichting ) . Wordt de \n",
      " aanwijzing niet nageleefd , dan kan zij in de eerste plaats bestuursrechtelijk worden gehandhaafd , \n",
      " bijvoorbeeld met een last onder bestuursdwang of een last onder dwangsom ( artikel 58u , eerste lid , \n",
      " onder b ) . Daarbij geldt dat bestuursrechtelijk een beginselplicht tot handhaving bestaat . Boetes zijn \n",
      " strafrechtelijk van aard en , zoals is toegelicht in 8 7.1 van de memorie van toelichting , een ultimum \n",
      " remedium . In een concreet geval is het aan de officier van \u001b[4m\u001b[96mjustitie\u001b[96m\u001b[0m en eventueel de strafrechter of de \n",
      " aanwijzing ( en daarmee dus de in principe daaraan voorafgaande adviezen en handreikingen ) ook op \n",
      " die wijze wordt gehandhaafd . \n",
      " 156 — D66 \n",
      " Hoe groot is de persoonlijke afwegingsruimte van zorgprofessionals om hiervan af te wijken , indien zij \n",
      " dit van belang vinden voor het verlenen van goede en dus ook veilige zorg ? \n",
      " Indien het voor een zorgaanbieder van belang is in verband met het verlenen van goede of \n",
      " verantwoorde zorg , kan hij van een richtlijn afwijken . De IGJ houdt hier in haar toezicht rekening \n",
      " mee . Belangrijk is dat de zorgaanbieder dit beargumenteerd en navolgbaar doet . \n",
      " 157 - D66 \n",
      " De leden van voornoemde fractie wijzen op het belang van een goede proportionaliteitsafweging bij de \n",
      " maatregelen door zorgaanbieders bij het voorkomen van de verspreiding van het coronavirus . Hoe is \n",
      " wettelijk geborgd dat maatregelen van zorgaanbieders bijvoorbeeld niet zo ver kunnen gaan dat het \n",
      " bewoners niet wordt toegestaan om een zorginstelling te verlaten , zoals aangegeven wordt in de \n",
      " memorie van toelichting ? \n",
      " Het is mogelijk dat een zorgaanbieder bewoners adviseert binnen te blijven en familie , vrienden en \n",
      " kennissen van bewoners adviseert niet op bezoek te komen . Indien bewoners en bezoekers daaraan \n",
      " vrijwillig medewerking verlenen , is daar geen bezwaar tegen . Een zorgaanbieder kan echter niet als \n",
      " \u001b[4m\u001b[96malgemene\u001b[96m\u001b[0m maatregel de bewoners gedwongen binnenhouden . Ook bij ministeriële regeling zal dat niet \n",
      " geregeld kunnen worden . Er zou dan sprake zijn van vrijheidsontneming , waarvoor in dit wetsvoorstel \n",
      " geen wettelijke basis is opgenomen . Het verlenen van zorg berust immers zoveel mogelijk op \n",
      " vrijwilligheid . Indien een cliënt of patiënt op grond van de Wet zorg en dwang of de Wet verplichte \n",
      " geestelijke gezondheidszorg in een instelling is opgenomen , kan hij wel op individueel niveau worden \n",
      " verplicht binnen te blijven , maar uitsluitend indien zijn gedrag als gevolg van een psychogeriatrische \n",
      " 59 \n",
      " 29107118 0076 \n",
      " correctq\n",
      "precision = 0.96875, recall = 0.6549295774647887, f1 = 0.7815126050420168\n",
      "{'correct': 178, 'incorrect': 0, 'partial': 16, 'missing': 106, 'spurious': 14, 'abbr': 18, 'ocr': 0, 'whitespace': 5, 'minister': 6, 'other': 91, 'precision': 0.96875, 'recall': 0.6549295774647887, 'f1': 0.7815126050420168}\n"
     ]
    }
   ],
   "source": [
    "results = evaluateMinistries(nlp_ministries, minList)\n",
    "\n",
    "results = calcResultsMinistries(results)\n",
    "\n",
    "with open('..\\\\data\\\\results\\\\ministries_results,json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-ready",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Missing things in situations like this: RVO/LNV. LNV should be have been caught here. This might be caused by the fact that spacy works with tokens/words in stead of individual letters. Places with a lot of extra newlines or spaces within the name of a ministry will also trip up the model. No context also doesnt help\n",
    "\n",
    "when training I specificly excluded the minister variants of the ministries. Therefore these aren't counted as missing if the model doesn't find them but will be counted as spurious if the the model does find them.\n",
    "\n",
    "The data the model was trained on means that it easily recoginizes ministries that have a lot to do with covid like volksgezondheid, but less so for others like landbouw. EZK (economics and climate) specifically doesn't want to be captured\n",
    "\n",
    "The type of text doesnt lend itself very well to NER. A lot of times the abbriviations of the ministries are listed without any contex to what it is. NER uses information about the surrounding words to predict what the word is. If there are no surrounding words, no context, predictions are going to be difficult\n",
    "\n",
    "ministerie SZW en EZK was counted as two partially correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-qualification",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
