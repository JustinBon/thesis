{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "impossible-premium",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\cupy\\_environment.py:214: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  'CUDA path could not be detected.'\n",
      "C:\\Users\\justin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\cupy\\_environment.py:214: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  'CUDA path could not be detected.'\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span, DocBin\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cognitive-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"nl_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metropolitan-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_ministries = spacy.load(\"..\\\\data\\\\spacy labeled\\\\output\\\\model-last\")\n",
    "df = pd.read_csv('..\\\\data\\\\ocred\\\\files_df.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-engagement",
   "metadata": {},
   "source": [
    "# dates\n",
    "This first part will be the evalutation for the base dates extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "prepared-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = ['januari', 'februari', 'maart', 'april', 'mei', 'juni', 'juli', 'augustus', 'september', 'oktober', 'november', 'december',\n",
    "         'january', 'february', 'march', 'april', 'may', 'june', 'juli', 'august', 'september', 'october', 'november', 'december',\n",
    "         'jan', 'feb', 'mrt', 'apr', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "days = ['maandag', 'dinsdag', 'woensdag', 'donderdag', 'vrijdag', 'zaterdag', 'zondag',\n",
    "       'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "sent = ['datum', 'verzonden', 'sent', 'date', 'received']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "surgical-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printHilight(string):\n",
    "    print('\\x1b[1;31m'+string + ' ' +'\\x1b[0m', end='')\n",
    "    \n",
    "def showMatches(doc, matches, regexMatches):   \n",
    "    indexOfMatches = []\n",
    "    for matchid, start, end in matches:\n",
    "        for i in range(start, end):\n",
    "            indexOfMatches.append(i)\n",
    "            \n",
    "    indexOfMatches = set(indexOfMatches)\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.i in indexOfMatches:\n",
    "            printHilight(str(token.text))\n",
    "        else:\n",
    "            if token.text in regexMatches:\n",
    "                printHilight(str(token.text))\n",
    "            else:\n",
    "                print(token, end=' ')\n",
    "    \n",
    "    return\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "sharp-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(dates, sep, pat):\n",
    "    goodDates = []\n",
    "    for date in dates:\n",
    "        date = date.replace(' ', '')\n",
    "        try:\n",
    "            date = date.replace(sep, ' ')\n",
    "            datetime.strptime(date, pat)\n",
    "            goodDates.append(date.replace(' ', sep))\n",
    "        except:\n",
    "            try:\n",
    "                if len(date.split(' ')) == 3 and len(date.split(' ')[2]) == 2:\n",
    "                    datetime.strptime(date, '%d %m %y')\n",
    "                    goodDates.append(date.replace(' ', sep))\n",
    "            except:\n",
    "                pass     \n",
    "    return goodDates\n",
    "            \n",
    "\n",
    "def regexMatcher(text):\n",
    "    results = []\n",
    "    \n",
    "    results += validate(re.findall('[0-3]{0,1}[0-9]\\/[0-1]{0,1}[0-9]', text), '/', '%d %m')\n",
    "\n",
    "    results += validate(re.findall('[0-3]{0,1}[0-9]\\/[0-1]{0,1}[0-9]\\/[0-9]{2,4}', text), '/', '%d %m %Y')\n",
    "\n",
    "    results += validate(re.findall('[0-3]{0,1}[0-9]-[0-1]{0,1}[0-9]', text), '-', '%d %m')\n",
    "\n",
    "    results += validate(re.findall('[0-3]{0,1}[0-9]-[0-1]{0,1}[0-9]-[0-9]{2,4}', text), '-', '%d %m %Y')\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-authorization",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "resistant-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputHandling(message):\n",
    "    while(True):\n",
    "        i = input(message)\n",
    "        if i == 'exit':\n",
    "            return -1\n",
    "        \n",
    "        elif i == '':\n",
    "            return 0\n",
    "        \n",
    "        try:\n",
    "            i = int(i)\n",
    "            return i\n",
    "        \n",
    "        except:\n",
    "            print(\"input number, exit or nothing\")\n",
    "        \n",
    "\n",
    "def evaluate(nlp):\n",
    "    \n",
    "    months = ['januari', 'februari', 'maart', 'april', 'mei', 'juni', 'juli', 'augustus', 'september', 'oktober', 'november', 'december',\n",
    "         'january', 'february', 'march', 'april', 'may', 'june', 'juli', 'august', 'september', 'october', 'november', 'december',\n",
    "         'jan', 'feb', 'mrt', 'apr', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "    days = ['maandag', 'dinsdag', 'woensdag', 'donderdag', 'vrijdag', 'zaterdag', 'zondag',\n",
    "           'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday',\n",
    "           'ma', 'di', 'wo', 'woe', 'do', 'vrij', 'za', 'zat', 'zo', 'vr']\n",
    "    \n",
    "    datesPattern = [{\"LOWER\" : {\"IN\" : days}, \"OP\" : \"?\"}, \n",
    "           {\"IS_DIGIT\": True}, \n",
    "           {\"LOWER\" : {\"IN\" : months}},\n",
    "           {\"IS_PUNCT\" : True, \"OP\" : \"?\", \"TEXT\":'.'},\n",
    "           {\"IS_DIGIT\": True, \"OP\" : \"?\"}]\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add(\"Dates\", [datesPattern])\n",
    "    \n",
    "    # cor = exact match, inc = match is wrong (wrong bounds or label), mis = missing match, spu = found something that isnt a mactch\n",
    "    results = {\n",
    "        'correct':0,\n",
    "        'incorrect':0,\n",
    "        'missing':0,\n",
    "        'spurious':0\n",
    "    }\n",
    "    \n",
    "    \n",
    "    while(True):\n",
    "        try:\n",
    "            print(sum(results.values()))\n",
    "            sample = df.sample(1)\n",
    "            print(sample.name.values[0], sample.page.values[0], '\\n\\n')\n",
    "            text = sample.text.values[0]\n",
    "            text = re.sub('\\n+', '\\n', text)\n",
    "            text = re.sub(' +', ' ', text)\n",
    "            doc = nlp(text)\n",
    "            matches = matcher(doc)\n",
    "\n",
    "            regexMatches = regexMatcher(text)\n",
    "\n",
    "            showMatches(doc, matches, regexMatches)\n",
    "\n",
    "            for case in results.keys():\n",
    "                result = inputHandling(case)\n",
    "                if result == -1:\n",
    "                    return results\n",
    "                else:\n",
    "                    results[case] += result\n",
    "\n",
    "            clear_output()\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "computational-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcResults(r):\n",
    "    precision = r['correct'] / (r['correct']+r['incorrect']+r['spurious'])\n",
    "    recall = r['correct'] / (r['correct']+r['incorrect']+r['missing'])\n",
    "    f1 = 2 * ((recall * precision)/(recall + precision))\n",
    "    print(f'precision = {precision}, recall = {recall}, f1 = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "running-optimization",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "dc034afbaede3d587451c7062fd857e7_bijlage-c2-openbaar-te-maken-documenten-nationaal 78 \n",
      "\n",
      "\n",
      "1056629 \n",
      " Ministerie van Financiën \n",
      " \n",
      " do . \u001b[1;31m12/8 \u001b[0m, 14.50 uur \n",
      " ( _ wqbo_x ) \n",
      " C XLea \n",
      " TER ADVISERING \n",
      " Aan \n",
      " de minister \n",
      " \\ ” \n",
      " # ‚ \n",
      " NO Belafspraak met MSZK over delen informatie RRF met \n",
      " sociale partners \n",
      " notitie \n",
      " Aanleiding \n",
      " Op \u001b[1;31m12 \u001b[0m\u001b[1;31maugustus \u001b[0mom 17:30u heeft u met MSZW een afspraak via Webex over zijn \n",
      " wens om meer informatie over RRF te delen met de sociale partners . \n",
      " Kern \n",
      " e MEZK spreekt op \u001b[1;31m25 \u001b[0m\u001b[1;31maugustus \u001b[0mmet sociale partners over het RRF . MSZW wil \n",
      " graag dat MEZK dan meer inhoud deelt uit de ambtelijke inventarisatie naar \n",
      " de mogelijke invulling van een RRP die in april is gedeeld met de formatie . \n",
      " s Wij raden u aan om tijdens het gesprek niet toe te geven aan zijn wens . U \n",
      " kunt de volgende argumenten gebruiken : \n",
      " o Het delen van de inhoud van de ambtelijke inventarisatie met SOPA's \n",
      " en/of parlement is niet conform afspraak in de MR waarin tot de \n",
      " inventarisatie besloten werd . Er is afgesproken om een inventarisatie te \n",
      " doen zonder brede maatschappelijke uitvraag , \n",
      " o Daarnaast zijn stukken die dienen als input voor de formatie \n",
      " vertrouwelijk . Inhoud delen of afstemmen met de sociale partners zou de \n",
      " vertrouwelijkheid van de formatie schaden . \n",
      " o De RRF-Verordening zegt weliswaar dat stakeholders betrokken moeten \n",
      " worden , maar schrijft niets voor over timing en aard van consultatie . \n",
      " o Delen is ook onwenselijk indien het slechts gaat om een presentatie op \n",
      " hoofdlijnen , met bijvoorbeeld alleen de titels van de voorstellen op de \n",
      " slides . Dit kan alleen maar leiden tot meer druk vanuit de sociale partners \n",
      " om het hele pakket te delen , of een lobby voor aanpassingen in de media , \n",
      " o Indien SZW wil afwijken van de afspraken die zijn gemaakt in de MR , dan \n",
      " moet dit opnieuw via de MR politiek worden voorgelegd . Daarna moet ook \n",
      " de Kamer eerst worden geïnformeerd . \n",
      " s Eventueel kan als alternatief de brief van juli gedeeld worden waarin u de \n",
      " Eerste Kamer op hoofdlijnen informeerde over de voorbereidingen voor het \n",
      " RRP . In deze brief wordt al een aantal beleidsterreinen genoemd ( zie bijlage : \n",
      " onder andere zorg , arbeidsmarkt , onderwijs , klimaat en groene transitie , \n",
      " digitale transitie , pensioenen , woningmarkt en het tegengaan van \n",
      " belastingplanning en witwassen ) maar geen specifieke voorstellen . \n",
      " s MSZW belt donderdagochtend ook met MEZK . Wij hebben van EZK vernomen \n",
      " dat MEZK ook echt niet wil delen , Zie toelichting voor een uitgebreidere inzet . \n",
      " « Ambtelijk EZK heeft MEZK geadviseerd om nog te bellen met u voorafgaand \n",
      " aan het gesprek met MSZW , om de gemeenschappelijke lijn te bespreken . Wij \n",
      " denken dat dit geen kwaad kan , als dit in uw agenda past . \n",
      " Directie Algemene \n",
      " Financiële en Economische \n",
      " Politiek \n",
      " Inlichtingen \n",
      " T L 1[0.2e \n",
      " ET .75‘e——]l \n",
      " _ TUZe _ pminfin.nl \n",
      " www.minfin.nl \n",
      " Direct contact \n",
      " ID2ZH7109.2le \n",
      " M _ TU2Z.e \n",
      " Datum \n",
      " \u001b[1;31m10 \u001b[0m\u001b[1;31maugustus \u001b[0m\u001b[1;31m2021 \u001b[0m\n",
      " Notitienummer \n",
      " 2021-00001i64575 \n",
      " Auteur \n",
      " tuzegze \n",
      " Van \n",
      " AFEP \n",
      " Pagina l van 3 \n",
      " 00026 \n",
      " correct1\n",
      "incorrect\n",
      "missingexit\n",
      "precision = 0.9197860962566845, recall = 0.8911917098445595, f1 = 0.9052631578947369\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(nlp)\n",
    "calcResults(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "reverse-johnson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct': 172, 'incorrect': 8, 'missing': 13, 'spurious': 7}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-fence",
   "metadata": {},
   "source": [
    "removed all access newlines and spaces\n",
    "\n",
    "Part of the reason not all dates were caught was an oversight with american date formats. To validate the if a found match is actually a date, it needs a date format to compare the match to. Only the dd-mm-yyyy format was checked and not the american format of mm-dd-yyyy with the month before the year. This means it excludes dates like 04-14-2022 as this cannot be a date in the dd-mm-yyyy format because there obviously isn't a 14th month. In the american system this is just april 14th 2022.\n",
    "\n",
    "Another reason for not finding some dates is OCR mistakes. For example, in one case the date that was supposed to be found was \"5/12/2021\" but in the OCR process that string was read as \"542/2021\" where the \"/\" and \"1\" were seen as one character, a 4.\n",
    "\n",
    "precision = 0.9197860962566845, recall = 0.8911917098445595, f1 = 0.9052631578947369"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-light",
   "metadata": {},
   "source": [
    "# Ministries\n",
    "This next part is the evalutation of the ministries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alternate-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMinisteries():\n",
    "    page = requests.get('https://nl.wikipedia.org/wiki/Lijst_van_Nederlandse_ministeries')\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find_all(\"td\")[-1]\n",
    "\n",
    "    results.find_all('a', href = True)\n",
    "    wikis = {}\n",
    "\n",
    "    abrr = []\n",
    "    for item in str(results.find_all('p')[0]).split('\\n')[:-1] + str(results.find_all('p')[1]).split('\\n')[1:-1]:\n",
    "        temp = re.findall('(?<=\\()(.*?)(?=\\))', item)\n",
    "        if temp == []:\n",
    "            abrr.append(None)\n",
    "        elif temp[-1] == 'Nederland':\n",
    "            abrr.append(None)\n",
    "            if 'Overzeese Gebiedsdelen' in item:\n",
    "                abrr.append(None)\n",
    "        else:\n",
    "            abrr.append(temp[-1].replace('&amp;', '&'))\n",
    "\n",
    "\n",
    "    counter = 0\n",
    "    for ministerie in results.find_all('a')[:12]:\n",
    "        wikis[ministerie.text] = {'Link': 'https://nl.wikipedia.org' + ministerie['href'], 'Abbriviation' : abrr[counter]}\n",
    "        counter += 1\n",
    "    \n",
    "    minList = list(wikis.keys()) + [wikis[x]['Abbriviation'] for x in wikis.keys()]\n",
    "    for x in minList:\n",
    "        temp+=x.replace(',', '').split(' ')\n",
    "    \n",
    "    return [x.lower() for x in temp if x != 'en' and x != '']\n",
    "minList = getMinisteries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "guilty-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printHilight(string):\n",
    "    print('\\x1b[1;31m'+string + ' ' +'\\x1b[0m', end='')\n",
    "\n",
    "def printHilightUnderline(string):\n",
    "    print('\\033[4m'+string + ' ' +'\\x1b[0m', end='')\n",
    "    \n",
    "def showMatchesMinistries(doc, minList):   \n",
    "    indexOfMatches = []\n",
    "    for ent in doc.ents:\n",
    "        for i in range(int(ent.start), int(ent.end)):\n",
    "            indexOfMatches.append(i)\n",
    "\n",
    "    indexOfMatches = set(indexOfMatches)\n",
    "\n",
    "    for token in doc:\n",
    "        flag = False\n",
    "        for mini in minList:\n",
    "            if token.text.lower() == mini:\n",
    "                flag = True\n",
    "                break\n",
    "        \n",
    "        if token.i in indexOfMatches:\n",
    "            printHilight(str(token.text))\n",
    "            \n",
    "        elif flag:\n",
    "            printHilightUnderline(str(token.text))\n",
    "            \n",
    "        else:\n",
    "            print(token, end=' ')\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "imported-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputHandling(message):\n",
    "    while(True):\n",
    "        i = input(message)\n",
    "        if i == 'q':\n",
    "            return -1\n",
    "        \n",
    "        elif i == '':\n",
    "            return 0\n",
    "        \n",
    "        try:\n",
    "            i = int(i)\n",
    "            return i\n",
    "        \n",
    "        except:\n",
    "            print(\"input number, exit or nothing\")\n",
    "\n",
    "def evaluateMinistries(nlp, minList):\n",
    "    # cor = exact match, inc = match is wrong (wrong bounds or label), mis = missing match, spu = found something that\n",
    "    # isnt a mactch, \n",
    "    results = {\n",
    "        'correct':0,\n",
    "        'incorrect':0,\n",
    "        'missing':0,\n",
    "        'spurious':0,\n",
    "        'partial':0\n",
    "    }\n",
    "    \n",
    "    minList = set(minList)\n",
    "    while(True):\n",
    "        try:\n",
    "            sample = df.sample(1)\n",
    "            text = sample.text.values[0]\n",
    "            text = re.sub('\\n+', '\\n', text)\n",
    "            text = re.sub(' +', ' ', text)\n",
    "            for m in minList:\n",
    "                if m in text.split(' '):\n",
    "                    print(m, 'AHHHHHHHHHHHHHHHH')\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "            print(sum(results.values()))\n",
    "            print(sample.name.values[0], sample.page.values[0], '\\n\\n')\n",
    "            doc = nlp(text)\n",
    "            \n",
    "            showMatchesMinistries(doc, minList)\n",
    "\n",
    "            for case in results.keys():\n",
    "                result = inputHandling(case)\n",
    "                if result == -1:\n",
    "                    return results\n",
    "                else:\n",
    "                    results[case] += result\n",
    "\n",
    "            clear_output()\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "norwegian-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcResults(r):\n",
    "    precision = (r['correct'] + (0.5 * r['partial'])) / (r['correct']+r['incorrect']+r['spurious'])\n",
    "    recall = (r['correct'] + (0.5 * r['partial'])) / (r['correct']+r['incorrect']+r['missing'])\n",
    "    f1 = 2 * ((recall * precision)/(recall + precision))\n",
    "    print(f'precision = {precision}, recall = {recall}, f1 = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "double-assurance",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zaken AHHHHHHHHHHHHHHHH\n",
      "96\n",
      "6762214604a58986abf9cc852b4202e9_bijlagen-deel-7-bij-besluit-wob-verzoek-over-covid-19 59 \n",
      "\n",
      "\n",
      "529309 \n",
      " \n",
      " \n",
      " | Crisiscoördinator DCC \u001b[1;31mVWS \u001b[0m| \n",
      " Ministerie van Volksgezondheld , \u001b[4mWelzijn \u001b[0men \u001b[4mSport \u001b[0m| Directie Publieke Gezondheid | \n",
      " Afdeling Crisisbeheersing en Infectieziekten | Etage : 8 flex \n",
      " 102 _ G \n",
      " Parnassusplein 5| 2511 VX | Den Haag | \n",
      " Postbus 20350 | 2500 EJ | Den Haag \n",
      " \n",
      " \n",
      " \n",
      " Van : NCC - NCTV \n",
      " Verzonden : woensdag 29 januari 2020 14:54:01 ( UTC+01:00 ) Amsterdam , Berlijn , Bern , Rome , Stockholm , Wenen \n",
      " Onderwerp : RECTIFICATIE uitnodiging IAO maandag 3 februari om 14.00 uur met betrekking tot de stand van \u001b[4mzaken \u001b[0mrondom de \n",
      " uitbraak van het Corona virus in China \n",
      " RECTIFICATIE : 14:00 uur i.p.v. 13.30 uur \n",
      " Geachte heer/mevrouw , \n",
      " Op verzoek van \u001b[1;31mVWS \u001b[0men NCTV nodig ik u uit voor een Interdepartementaal Afstemmings Overleg ( IAO ) op maandag 3 \n",
      " februari om 14.00 uur met betrekking tot de stand van \u001b[4mzaken \u001b[0mrondom de uitbraak van het Corona virus in China . \n",
      " De bijeenkomst vindt plaats bij het \u001b[1;31mMinisterie \u001b[0m\u001b[1;31mvan \u001b[0m\u001b[1;31mJustitie \u001b[0m\u001b[1;31men \u001b[0m\u001b[1;31mVeiligheid \u001b[0m, Turfmarkt 147 , 7e etage . NCTV , MCCb/ICCb- \n",
      " zaal . \n",
      " Eventuele stukken voor de vergadering worden ter plekke uitgedeeld . \n",
      " Graag ontvangen wij een bevestiging van uw aanwezigheid via onderstaand emailadres van het NCC . Vergeet niet om uw \n",
      " legitimatiebewijs mee te nemen . \n",
      " Buiten kantoortijden kunt zich melden bij de 24-uurs ingang . Deze is gelegen aan de Schedeldoekshaven 552 , aan de \n",
      " achterzijde van het gebouw , naast de parkeergarage . \n",
      " Met vriendelijke groet , \n",
      " Nationaal CrisisCentrum ( NCC ) \n",
      " E @nctv.minjenv.nl \n",
      " ( 10){2e ) ( algemeen nummer ) \n",
      " E ( ncident nummer ) \n",
      " \n",
      " ( 10)(2e ) \n",
      " \n",
      " Dit bericht kan informatie bevatten die niet voor u is bestemd . Indien u niet de geadresseerde bent of dit bericht \n",
      " abusievelijk aan u is toegezonden , wordt u verzocht dat aan de afzender te melden en het bericht te verwijderen . De Staat \n",
      " aanvaardt geen aansprakelijkheid voor schade , van welke aard ook , die verband houdt met risico's verbonden aan het \n",
      " elektronisch verzenden van berichten . \n",
      " \u001b[1;31mMinisterie \u001b[0m\u001b[1;31mvan \u001b[0m\u001b[1;31mJustitie \u001b[0m\u001b[1;31men \u001b[0m\u001b[1;31mVeiligheid \u001b[0m\n",
      " This message may contain information that is not intended for you . If you are not the addressee or if this message was sent \n",
      " to you by mistake , you are requested to inform the sender and delete the message . The State accepts no liability for \n",
      " damage of any kind resulting from the risks inherent in the electronic transmission of messages . \n",
      " test 4\n",
      "correct4\n",
      "incorrect\n",
      "missing1\n",
      "spurious\n",
      "partialexit\n",
      "input number, exit or nothing\n",
      "partialq\n",
      "precision = 0.96, recall = 0.7912087912087912, f1 = 0.8674698795180723\n"
     ]
    }
   ],
   "source": [
    "results = evaluateMinistries(nlp_ministries, minList)\n",
    "calcResults(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "continuing-republican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "t = nlp_ministries('het Ministerie is een beetje dom')\n",
    "tl = ['ministerie']\n",
    "for w in t:\n",
    "    print(str(w.text).lower() in tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "trained-cookbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wvc',\n",
       " 'algemene',\n",
       " 'zaken',\n",
       " 'binnenlandse',\n",
       " 'zaken',\n",
       " 'koninkrijksrelaties',\n",
       " 'buitenlandse',\n",
       " 'zaken',\n",
       " 'defensie',\n",
       " 'economische',\n",
       " 'zaken',\n",
       " 'klimaat',\n",
       " 'financiën',\n",
       " 'infrastructuur',\n",
       " 'waterstaat',\n",
       " 'justitie',\n",
       " 'veiligheid',\n",
       " 'landbouw',\n",
       " 'natuur',\n",
       " 'voedselkwaliteit',\n",
       " 'onderwijs',\n",
       " 'cultuur',\n",
       " 'wetenschap',\n",
       " 'sociale',\n",
       " 'zaken',\n",
       " 'werkgelegenheid',\n",
       " 'volksgezondheid',\n",
       " 'welzijn',\n",
       " 'sport',\n",
       " 'az',\n",
       " 'bzk',\n",
       " 'bz',\n",
       " 'def',\n",
       " 'ez',\n",
       " 'fin',\n",
       " 'i&w',\n",
       " 'j&v',\n",
       " 'lnv',\n",
       " 'ocw',\n",
       " 'szw',\n",
       " 'vws']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-cooking",
   "metadata": {},
   "source": [
    "Missing things in situations like this: RVO/LNV. LNV should be have been caught here. Places with a lot of extra newlines or spaces within the name of a ministry will also trip up the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-thriller",
   "metadata": {},
   "source": [
    "# SpaCy\n",
    "\n",
    "This next part is the spacy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "worldwide-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGroundTruth():\n",
    "    with open('..\\\\data\\\\ner labeled data\\\\test.conllu', 'r', encoding='utf8') as f:\n",
    "        ground = f.read()\n",
    "        ground = ground.split('\\n')\n",
    "        ground = [x.split('\\t') for x in ground]\n",
    "    \n",
    "    text = []\n",
    "    for word in ground:\n",
    "        try:\n",
    "            text.append(word[1])\n",
    "        except IndexError:\n",
    "            text.append('\\n')\n",
    "    \n",
    "\n",
    "    text = ' '.join(text)\n",
    "    return text, ground\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "text, ground = loadGroundTruth()\n",
    "doc = nlp(text[:1000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "martial-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcF1(tp, tn, fp, fn):\n",
    "    print(tp, tn, fp, fn)\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    f1 = 2 * ((recall * precision) / (recall + precision))\n",
    "    return recall, precision, f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "israeli-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalNER(ground, doc):\n",
    "    \n",
    "    groundIndex, docIndex = 0, 0\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    nerCats = ['FAC', 'PERSON', 'ORG', 'GPE', 'LOC']\n",
    "    groundCats = ['ORG', 'LOC', 'PER']\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            if str(doc[docIndex].text) != ground[groundIndex][1]:\n",
    "                \n",
    "                # checks for if the words are still in sync\n",
    "                if str(doc[docIndex + 1].text) != ground[groundIndex][1]:\n",
    "                    docIndex += 1\n",
    "                    continue\n",
    "                \n",
    "                elif str(doc[docIndex].text) != ground[groundIndex + 1][1]:\n",
    "                    groundIndex += 1\n",
    "                    continue\n",
    "                    \n",
    "                else:\n",
    "                    for j in range(docIndex-3,docIndex+3):\n",
    "                        print(doc[j], ground[j])\n",
    "                \n",
    "            else:\n",
    "                if doc[docIndex].ent_type_ == '' and ground[groundIndex][2] == 'O':\n",
    "                    tn += 1\n",
    "                    \n",
    "                elif doc[docIndex].ent_type_ in nerCats and ground[groundIndex][2] == 'O':\n",
    "                    fp += 1\n",
    "                    \n",
    "                elif doc[docIndex].ent_type_ in nerCats and ground[groundIndex][2] != 'O':\n",
    "                    tp += 1\n",
    "                    \n",
    "                elif doc[docIndex].ent_type_ == '' and ground[groundIndex][2] != 'O':\n",
    "                    fn += 1\n",
    "        \n",
    "        except IndexError:\n",
    "            pass\n",
    "        \n",
    "        groundIndex +=1\n",
    "        docIndex +=1\n",
    "        \n",
    "        if groundIndex > len(ground) and docIndex > len(doc):\n",
    "            print('good')\n",
    "            return calcF1(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "confidential-numbers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "1240 10349 47 185\n",
      "recall 0.8701754385964913\n",
      "precision 0.9634809634809635\n",
      "f1 0.9144542772861357\n"
     ]
    }
   ],
   "source": [
    "recall, precision, f1 = evalNER(ground, doc)\n",
    "print('recall', recall)\n",
    "print('precision', precision)\n",
    "print('f1', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "suspected-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcF1Strict(cor, inc, spu, mis):\n",
    "    print(cor,inc,spu,mis)\n",
    "    recall = cor / (cor+inc+mis)\n",
    "    precision = cor / (cor+inc+spu)\n",
    "    f1 = 2 * ((recall * precision) / (recall + precision))\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fleet-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalNERStrict(ground, doc):\n",
    "    \n",
    "    groundIndex, docIndex = 0, 0\n",
    "    cor, inc, spu, mis = 0, 0, 0, 0\n",
    "    \n",
    "    cats = {'ORG': ['ORG'],\n",
    "           'PER': ['PERSON'],\n",
    "           'LOC': ['FAC', 'GPE', 'LOC'],\n",
    "           'ORG': ['ORG'],\n",
    "           'MISC': ['FAC', 'PERSON', 'ORG', 'GPE', 'LOC']}\n",
    "    while True:\n",
    "        \n",
    "        try:\n",
    "            if str(doc[docIndex].text) != ground[groundIndex][1]:\n",
    "                \n",
    "                # checks for if the words are still in sync\n",
    "                if str(doc[docIndex + 1].text) != ground[groundIndex][1]:\n",
    "                    docIndex += 1\n",
    "                    continue\n",
    "                \n",
    "                elif str(doc[docIndex].text) != ground[groundIndex + 1][1]:\n",
    "                    groundIndex += 1\n",
    "                    continue\n",
    "                    \n",
    "                else:\n",
    "                    for j in range(docIndex-3,docIndex+3):\n",
    "                        print(doc[j], ground[j])\n",
    "                \n",
    "            else:\n",
    "                try:\n",
    "                    # true negative\n",
    "                    if doc[docIndex].ent_type_ == '' and ground[groundIndex][2] == 'O':\n",
    "                        pass\n",
    "                    \n",
    "                    # for categories that ground doesnt have\n",
    "                    elif doc[docIndex].ent_type_ not in cats['MISC'] + [''] and ground[groundIndex][2] == 'O':\n",
    "                        pass\n",
    "\n",
    "                    # spurious\n",
    "                    elif doc[docIndex].ent_type_ in cats['MISC'] and ground[groundIndex][2] == 'O':\n",
    "                        spu += 1\n",
    "\n",
    "                    # missing\n",
    "                    elif doc[docIndex].ent_type_ == '' and ground[groundIndex][2] != 'O':\n",
    "                        mis += 1\n",
    "\n",
    "                    # correct\n",
    "                    elif doc[docIndex].ent_type_ in cats[ground[groundIndex][2][2:]]:\n",
    "                        cor += 1\n",
    "\n",
    "                    # incorrect\n",
    "                    else:\n",
    "                        inc += 1\n",
    "                except KeyError:\n",
    "                    print(doc[docIndex], ground[groundIndex])\n",
    "\n",
    "        \n",
    "        except IndexError:\n",
    "            pass\n",
    "        \n",
    "        groundIndex +=1\n",
    "        docIndex +=1\n",
    "        \n",
    "        if groundIndex > len(ground) and docIndex > len(doc):\n",
    "            print('good')\n",
    "            return calcF1Strict(cor, inc, spu, mis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "registered-water",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "1168 261 47 185\n",
      "recall 0.7236679058240396\n",
      "precision 0.7913279132791328\n",
      "f1 0.7559870550161812\n"
     ]
    }
   ],
   "source": [
    "recall, precision, f1 = evalNERStrict(ground, doc)\n",
    "print('recall', recall)\n",
    "print('precision', precision)\n",
    "print('f1', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-kingdom",
   "metadata": {},
   "source": [
    "These are really good scores for the model, especially the first one. But we need to keep in mind that the permorance of a NER model can depend on the sort of text. It could be that the spaCy model was trained on documents that have a very high resemblance to this test set. The performance on the WOB document can be lower than these results suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-alloy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.4 64-bit",
   "language": "python",
   "name": "python36464bite3e9fea8e7cf4572b612ccf79ec495cf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
