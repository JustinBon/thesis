{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "meaning-thumbnail",
   "metadata": {},
   "source": [
    "## Problem statements\n",
    "\n",
    "For this extractor, I want to retrieve all mentions of miniseries in the WOB documents. There are a lot of different ministeries to extract all with their own abbriviations, so in this notebook I will explore to what extend it is possible to extract this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-promise",
   "metadata": {},
   "source": [
    "## Approach\n",
    "\n",
    "I decided to use a different approach as to what I did with the dates extractor. For the dates I mostly used a rulebase system. For this I will use gazetteers because there aren't a lot of ministeries to extract. Writing them down is not a long process and this will likely give better results than a rulebased system. The rulebased system might have to make sacrifices in accuracy in one area to get better results in others or you would have to make special cases for all ministeries and in that case you're basically using gazetteers.\n",
    "\n",
    "### The documents\n",
    "- [Document 1](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/0068ed0b40cca6270f857d2614cc63c0_besluit.pdf.text)\n",
    "- [Document 2](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/0068ed0b40cca6270f857d2614cc63c0_document.pdf.text)\n",
    "- [Document 3](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/0335b3f498dbbd7c537ad23abe8c08dc_deelbesluit-1-wob-verzoek-dd-11-augustus-2021-inzake-het-europees-herstelfonds.pdf.text)\n",
    "- [Document 4](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/07e2b274045cb5b4f54371a3c905cae9_wobverzoek-mccb-catshuis.pdf.text)\n",
    "- [Document 5](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/17967f10340f6de2a79ba984209b4a2c_besluit.pdf.text)\n",
    "- [Document 6](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/2c4079ccaad78e8d2cb494681ae79928_stukken-bij-besluit-wob-verzoek-notities-besluitvorming-coronacrisis-20.pdf.text)\n",
    "- [Document 7](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/3ee644b02189ec45794dd998ac5da5b5_besluit.pdf.text)\n",
    "- [Document 8](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/40f5564f839324b9af20c295dd261007_inventarislijst-eerste-deelbesluit.pdf.text)\n",
    "- [Document 9](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/41fedde7ea03bdd9ac5cd92c7f7cfd43_documenten.pdf.text)\n",
    "- [Document 10](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/439285231fa523a74c430da4a2704fab_deels-openbare-documenten.pdf.text)\n",
    "- [Document 11](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/4991dc6aed6e1369f58e6bc1996d5e2d_paginas-van-samengevoegd-document-850-paginas-met-uitgestelde-verstrekking-deel-1.pdf.text)\n",
    "- [Document 12](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/4991dc6aed6e1369f58e6bc1996d5e2d_paginas-van-samengevoegd-document-850-paginas-met-uitgestelde-verstrekking-deel-2.pdf.text)\n",
    "- [Document 13](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/4991dc6aed6e1369f58e6bc1996d5e2d_paginas-van-samengevoegd-document-850-paginas-met-uitgestelde-verstrekking-deel-3.pdf.text)\n",
    "- [Document 14](https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/4991dc6aed6e1369f58e6bc1996d5e2d_paginas-van-samengevoegd-document-850-paginas-met-uitgestelde-verstrekking-deel-4.pdf.text)\n",
    "\n",
    "As to the selection of documents, some of the documents didn't have a single mention of a ministery so I excluded those. I went through a number of documents until I had enough examples. The results can be found in [This text file](https://github.com/JustinBon/thesis/blob/main/data/ministeries.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spoken-logistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "maritime-means",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baselink = '(https://github.com/JustinBon/thesis/blob/main/data/covid%20wob%20text%20without%20ocr/'\n",
    "\n",
    "with open('..\\\\data\\\\ministeries.txt', 'r', encoding='utf-8') as f:\n",
    "    m = f.read()\n",
    "    m = m.split('\\n\\n')\n",
    "    \n",
    "counter = 0\n",
    "nfile = 0\n",
    "for file in m:\n",
    "    nfile += 1\n",
    "    file = file.split('\\n')\n",
    "#     print(f'- [Document {nfile}]' + baselink + file[0] + '.text)')\n",
    "    counter += len(file) -1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interim-insertion",
   "metadata": {},
   "source": [
    "To get a list of all of the ministeries, I took [The list that wikipedia provides](https://nl.wikipedia.org/wiki/Lijst_van_Nederlandse_ministeries). This has a list of all ministeries of the current government and all the ministeries that do not exist anymore which is very convinient. Also, wikipedia provides the links to the individual wiki pages of the ministeries as well so I can imidiatly link to them too.  I used beautifulsoup to get this data.\n",
    "\n",
    "\n",
    "\n",
    "CORRECTION:\n",
    "\n",
    "After testing, it is way better for the accuracy of the matcher to only look at the current ministeries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "sized-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets labeled data\n",
    "# also used for getting names of documents used\n",
    "\n",
    "def getData():\n",
    "    with open('..\\\\data\\\\ministeries.txt', 'r', encoding='utf-8') as f:\n",
    "        m = f.read()\n",
    "        m = m.split('\\n\\n')\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "floating-south",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get list of ministeries from wikipedia\n",
    "\n",
    "def getMinisteries():\n",
    "    page = requests.get('https://nl.wikipedia.org/wiki/Lijst_van_Nederlandse_ministeries')\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find_all(\"td\")[-1]\n",
    "\n",
    "    results.find_all('a', href = True)\n",
    "    wikis = {}\n",
    "\n",
    "    abrr = []\n",
    "    for item in str(results.find_all('p')[0]).split('\\n')[:-1] + str(results.find_all('p')[1]).split('\\n')[1:-1]:\n",
    "        temp = re.findall('(?<=\\()(.*?)(?=\\))', item)\n",
    "        if temp == []:\n",
    "            abrr.append(None)\n",
    "        elif temp[-1] == 'Nederland':\n",
    "            abrr.append(None)\n",
    "            if 'Overzeese Gebiedsdelen' in item:\n",
    "                abrr.append(None)\n",
    "        else:\n",
    "            abrr.append(temp[-1].replace('&amp;', '&'))\n",
    "\n",
    "\n",
    "    counter = 0\n",
    "    for ministerie in results.find_all('a')[:12]:\n",
    "        wikis[ministerie.text] = {'Link': 'https://nl.wikipedia.org' + ministerie['href'], 'Abbriviation' : abrr[counter]}\n",
    "        counter += 1\n",
    "\n",
    "    return wikis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "devoted-klein",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load hand-labeled data\n",
    "\n",
    "def getLabeledData():\n",
    "    m = getData()\n",
    "        \n",
    "    labeledMinisteries = {}\n",
    "    for file in m:\n",
    "        lines = file.split('\\n')\n",
    "        \n",
    "        labeledMinisteries[lines[0]] = {}\n",
    "        \n",
    "        for line in lines[1:]:\n",
    "            line = line.lower()\n",
    "            if line in labeledMinisteries[lines[0]]:\n",
    "                labeledMinisteries[lines[0]][line] += 1\n",
    "            else:\n",
    "                labeledMinisteries[lines[0]][line] = 1\n",
    "\n",
    "\n",
    "    return labeledMinisteries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "dimensional-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find ministeries in the text\n",
    "\n",
    "def findMinisteries():\n",
    "    ministeries = getMinisteries()\n",
    "    \n",
    "    abrr = [ministeries[x]['Abbriviation'] for x in ministeries if ministeries[x]['Abbriviation'] != None]\n",
    "    \n",
    "    allMinisteries = list(ministeries.keys()) + abrr\n",
    "    \n",
    "    \n",
    "    found = {}\n",
    "    \n",
    "    for file in getData():\n",
    "        \n",
    "        fileName = file.split('\\n')[0]\n",
    "        found[fileName] = {}\n",
    "        with open('..\\\\data\\\\covid wob text without ocr\\\\' + fileName +'.txt', 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            text = re.sub(' +', ' ', text)\n",
    "            text = text.lower()\n",
    "        \n",
    "        for ministerie in allMinisteries:\n",
    "            temp = re.findall('ministerie van ' + ministerie.lower(), text)\n",
    "            if temp != []:\n",
    "                found[fileName][ministerie.lower()] = len(temp)\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "established-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show with which ministeries i made mistakes\n",
    "# not used currently\n",
    "\n",
    "def showError(error, found, labeled):\n",
    "    \n",
    "    for err in error:\n",
    "        f = 0\n",
    "        l = 0\n",
    "        for file in found:\n",
    "            try:\n",
    "                f += found[file][err]\n",
    "            except:\n",
    "                f += 0\n",
    "            \n",
    "            try:\n",
    "                l += labeled[file][err]\n",
    "            except:\n",
    "                l += 0\n",
    "        \n",
    "        print(f'ministerie: {err}, matches: {f}, labeled: {l}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "stuck-consistency",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 10 124\n",
      "recall 0.3768844221105528\n",
      "precision 0.8823529411764706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate preformance\n",
    "\n",
    "def preformance():\n",
    "    labeled = getLabeledData()\n",
    "    found = findMinisteries()\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    fpList = []\n",
    "    fnList = []\n",
    "    \n",
    "    \n",
    "    for file in found:\n",
    "        \n",
    "        for ministerie in found[file]:\n",
    "            if ministerie not in labeled[file]:\n",
    "                fp += found[file][ministerie]\n",
    "                fpList.append(ministerie)\n",
    "                \n",
    "            elif found[file][ministerie] == labeled[file][ministerie]:\n",
    "                tp += found[file][ministerie]\n",
    "                \n",
    "            elif found[file][ministerie] > labeled[file][ministerie]:\n",
    "                tp += labeled[file][ministerie]\n",
    "                fp += found[file][ministerie] - labeled[file][ministerie]\n",
    "                fpList.append(ministerie)\n",
    "                \n",
    "            elif found[file][ministerie] < labeled[file][ministerie]:\n",
    "                tp += found[file][ministerie]\n",
    "                fn += labeled[file][ministerie] - found[file][ministerie]\n",
    "                fnList.append(ministerie)\n",
    "    \n",
    "        for ministerie in labeled[file]:\n",
    "            if ministerie not in found:\n",
    "                fn += labeled[file][ministerie]\n",
    "                fnList.append(ministerie)\n",
    "                \n",
    "    \n",
    "\n",
    "    print(tp, fp, fn)\n",
    "    print('recall', tp / (tp + fn))\n",
    "    print('precision', tp / (tp + fp))\n",
    "    print('')\n",
    "    \n",
    "preformance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-toyota",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "It is easy to find correct matches for ministeries when using gazetteers. The precision of this test is 0.882. Most all of the matches that were found are actually ministeries. However the recall of the matcher is very bad at 0.377. The matcher doesnt even find half of all the ministeries that were in the text. The reason for this is clear. It has to do with summations as abbriviations. \n",
    "\n",
    "Within the texts, a lot of summations of ministeries are used. For example: \"de ministeries van VWSS, JenV, en BZK\". In this case none of these will abbreviations of ministeries will be matched. The matcher looks for \"ministerie van {name of ministerie}\". VWSS will not be matched because ministeries is plural in stead of singular and JenV and BZK will not be matched because these are not preceded by \"ministerie van \". A solution for this could be to not look for the preceding \"ministerie van \", however, if this is done, all of those abbriviations will be matched outside of context. The abbriviation of the ministery of defence for example, is \"def\" so the matcher will find all occurences of the three letters \"def\". With this modification the recall will actually increase to a whopping 0.458 but the precision will decrease to a meager 0.122. So this is not a solution. \n",
    "\n",
    "I also tested if the it would help to at least find the VWSS in the example by also looking at the plural of ministerie but that decreased the precision more than it increased the recall. \n",
    "\n",
    "The last solution is the \"best\". This completely ignores the abbriviations and just looks for the names if the ministeries without the preceding \"ministerie van \". This actually increases the recall to 0.435 but it also decreases the precision to 0.732. This is because it will also find random mentions of the words \"financien\" and \"defensie\" and others. I don't think that that is worth it. In this case I would rather have more confidance in what I what I find to be correct than finding everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
